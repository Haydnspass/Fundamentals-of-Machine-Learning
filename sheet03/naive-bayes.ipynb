{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "import time\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_subset(condition, x, y):\n",
    "    sub_ix = np.where((y == condition[0]) | (y == condition[1]))\n",
    "    y_sub = (y[sub_ix]).squeeze()\n",
    "    # rename labels\n",
    "    y_sub[y_sub == condition[0]] = 0\n",
    "    y_sub[y_sub == condition[1]] = 1\n",
    "    x_sub = (x[sub_ix, :]).squeeze()\n",
    "    return x_sub, y_sub\n",
    "\n",
    "\n",
    "def red_dim(x, features=[10, 60]):\n",
    "    x_red = np.zeros((x.shape[0], len(features)))\n",
    "    x_red[:, 0] = x[:, features[0]]\n",
    "    x_red[:, 1] = x[:, features[1]]\n",
    "\n",
    "    return x_red\n",
    "\n",
    "\n",
    "def fit_naive_bayes(features, labels, bincount=0):\n",
    "    def filter_data(features, labels, c):\n",
    "        assert c in labels, 'Class is not in labels'\n",
    "        sub_ix = c == labels\n",
    "        return features[sub_ix], labels[sub_ix]\n",
    "\n",
    "    def histogram(xx, num_bins):\n",
    "        h, b = np.histogram(xx, bins=num_bins)\n",
    "        return h, b\n",
    "\n",
    "    def freedman_diaconis(X):\n",
    "        iqr = np.percentile(X, 75) - np.percentile(X, 25)  # X_3/4 quartile - X_1/4 quartile\n",
    "        if iqr == 0:\n",
    "            delta_x = float('nan')\n",
    "        else:\n",
    "            delta_x = (2 * iqr) / (np.power(len(X), 1 / 3))\n",
    "        return delta_x\n",
    "\n",
    "    if bincount == 0:\n",
    "        # loop over features and use reasonable freedman diaconis\n",
    "        bincount_helper = np.zeros(features.shape[1])\n",
    "        for i in range(features.shape[1]):\n",
    "            delta_x = freedman_diaconis(features[:, i])\n",
    "            bincount_helper[i] = np.ceil((np.max(features[:, i]) - np.min(features[:, i])) / delta_x)\n",
    "        # use median value neglecting nan\n",
    "        bincount = int(np.ceil(np.median(bincount_helper[np.invert(np.isnan(bincount_helper))])))\n",
    "\n",
    "    hist = np.zeros((len(labels), features.shape[1], bincount))\n",
    "    binning = np.zeros((len(labels), features.shape[1], bincount + 1))\n",
    "    for i, c in enumerate(labels):\n",
    "        features_sub, _ = filter_data(features, labels, c)\n",
    "        hist[i,:,:], binning[i,:,:] = histogram(features_sub, bincount)\n",
    "    return hist, binning\n",
    "\n",
    "\n",
    "def predict_naive_bayes(features, hist, binning):\n",
    "    l = np.nan * np.ones((features.shape[0], hist.shape[0], features.shape[1]), dtype=np.int)\n",
    "    # assign instance i to correct bin\n",
    "    for i in range(features.shape[0]):\n",
    "        for j in range(features.shape[1]):\n",
    "            for k in range(hist.shape[0]):\n",
    "                l[i, k, j] = np.floor((features[i,j] - binning[k,j,0])/binning[k,j,1])\n",
    "                if l[i, k, j] >= (binning.shape[2] - 1):\n",
    "                    l[i, k, j] += -1\n",
    "\n",
    "    # get N_l\n",
    "    p_h = np.zeros_like(l)\n",
    "    p = np.zeros_like(l[:,:,0])\n",
    "    for i in range(features.shape[0]):\n",
    "        for j in range(features.shape[1]):\n",
    "            for k in range(hist.shape[0]):\n",
    "                p_h[i, k, j] = hist[k, j, int(l[i, k, j])] / (np.sum(hist[k,j,:]) * binning[k,j,1])\n",
    "    for i in range(features.shape[0]):\n",
    "        for k in range(hist.shape[0]):\n",
    "            p[i, k] = np.prod([p_h[i, k, j] for j in range(features.shape[1])])\n",
    "    y = np.nan * np.ones(features.shape[0], dtype=np.int)\n",
    "    y = np.argmax(p, 1)\n",
    "    return p, y\n",
    "\n",
    "\n",
    "def pred_quality(pred, truth):\n",
    "    is_eq = (pred == truth)\n",
    "    pass_rate = np.sum(is_eq) / is_eq.__len__()\n",
    "    err_rate = 1-pass_rate\n",
    "    return pass_rate, err_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "print(digits.keys())\n",
    "\n",
    "data = digits[\"data\"]\n",
    "images = digits[\"images\"]\n",
    "target = digits[\"target\"]\n",
    "target_names = digits[\"target_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction pass rate:  0.825688073394  ---- error rate:  0.174311926606\n"
     ]
    }
   ],
   "source": [
    "x, y = use_subset([1, 7], data, target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "hist, binning = fit_naive_bayes(X_train, y_train)\n",
    "_, y_pred = predict_naive_bayes(X_test, hist, binning)\n",
    "passed, errored = pred_quality(y_pred, y_test)\n",
    "print('Prediction pass rate: ', passed, ' ---- error rate: ', errored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction pass rate:  0.614678899083  ---- error rate:  0.385321100917\n"
     ]
    }
   ],
   "source": [
    "data = red_dim(data)\n",
    "x, y = use_subset([1, 7], data, target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "\n",
    "hist, binning = fit_naive_bayes(X_train, y_train)\n",
    "_, y_pred = predict_naive_bayes(X_test, hist, binning)\n",
    "passed, errored = pred_quality(y_pred, y_test)\n",
    "print('Prediction pass rate: ', passed, ' ---- error rate: ', errored)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
